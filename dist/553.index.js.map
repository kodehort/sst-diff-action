{"version":3,"file":"553.index.js","mappings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jxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjVA;AACA;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACjIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChCA;AACA;AACA;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACVA;AACA;AACA;AACA;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/XA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/adm-zip.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/headers/entryHeader.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/headers/index.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/headers/mainHeader.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/methods/deflater.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/methods/index.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/methods/inflater.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/methods/zipcrypto.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/util/constants.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/util/errors.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/util/fattr.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/util/fileSystem.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/util/index.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/util/utils.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/zipEntry.js","webpack://sst-diff-action/./node_modules/.pnpm/adm-zip@0.5.10/node_modules/adm-zip/zipFile.js","webpack://sst-diff-action/./node_modules/.pnpm/@vercel+ncc@0.36.1/node_modules/@vercel/ncc/dist/ncc/@@notfound.js","webpack://sst-diff-action/./node_modules/.pnpm/sst@2.11.14/node_modules/sst/runtime/handlers/java.js"],"sourcesContent":["const Utils = require(\"./util\");\nconst pth = require(\"path\");\nconst ZipEntry = require(\"./zipEntry\");\nconst ZipFile = require(\"./zipFile\");\n\nconst get_Bool = (val, def) => (typeof val === \"boolean\" ? val : def);\nconst get_Str = (val, def) => (typeof val === \"string\" ? val : def);\n\nconst defaultOptions = {\n    // option \"noSort\" : if true it disables files sorting\n    noSort: false,\n    // read entries during load (initial loading may be slower)\n    readEntries: false,\n    // default method is none\n    method: Utils.Constants.NONE,\n    // file system\n    fs: null\n};\n\nmodule.exports = function (/**String*/ input, /** object */ options) {\n    let inBuffer = null;\n\n    // create object based default options, allowing them to be overwritten\n    const opts = Object.assign(Object.create(null), defaultOptions);\n\n    // test input variable\n    if (input && \"object\" === typeof input) {\n        // if value is not buffer we accept it to be object with options\n        if (!(input instanceof Uint8Array)) {\n            Object.assign(opts, input);\n            input = opts.input ? opts.input : undefined;\n            if (opts.input) delete opts.input;\n        }\n\n        // if input is buffer\n        if (Buffer.isBuffer(input)) {\n            inBuffer = input;\n            opts.method = Utils.Constants.BUFFER;\n            input = undefined;\n        }\n    }\n\n    // assign options\n    Object.assign(opts, options);\n\n    // instanciate utils filesystem\n    const filetools = new Utils(opts);\n\n    // if input is file name we retrieve its content\n    if (input && \"string\" === typeof input) {\n        // load zip file\n        if (filetools.fs.existsSync(input)) {\n            opts.method = Utils.Constants.FILE;\n            opts.filename = input;\n            inBuffer = filetools.fs.readFileSync(input);\n        } else {\n            throw new Error(Utils.Errors.INVALID_FILENAME);\n        }\n    }\n\n    // create variable\n    const _zip = new ZipFile(inBuffer, opts);\n\n    const { canonical, sanitize } = Utils;\n\n    function getEntry(/**Object*/ entry) {\n        if (entry && _zip) {\n            var item;\n            // If entry was given as a file name\n            if (typeof entry === \"string\") item = _zip.getEntry(entry);\n            // if entry was given as a ZipEntry object\n            if (typeof entry === \"object\" && typeof entry.entryName !== \"undefined\" && typeof entry.header !== \"undefined\") item = _zip.getEntry(entry.entryName);\n\n            if (item) {\n                return item;\n            }\n        }\n        return null;\n    }\n\n    function fixPath(zipPath) {\n        const { join, normalize, sep } = pth.posix;\n        // convert windows file separators and normalize\n        return join(\".\", normalize(sep + zipPath.split(\"\\\\\").join(sep) + sep));\n    }\n\n    return {\n        /**\n         * Extracts the given entry from the archive and returns the content as a Buffer object\n         * @param entry ZipEntry object or String with the full path of the entry\n         *\n         * @return Buffer or Null in case of error\n         */\n        readFile: function (/**Object*/ entry, /*String, Buffer*/ pass) {\n            var item = getEntry(entry);\n            return (item && item.getData(pass)) || null;\n        },\n\n        /**\n         * Asynchronous readFile\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param callback\n         *\n         * @return Buffer or Null in case of error\n         */\n        readFileAsync: function (/**Object*/ entry, /**Function*/ callback) {\n            var item = getEntry(entry);\n            if (item) {\n                item.getDataAsync(callback);\n            } else {\n                callback(null, \"getEntry failed for:\" + entry);\n            }\n        },\n\n        /**\n         * Extracts the given entry from the archive and returns the content as plain text in the given encoding\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param encoding Optional. If no encoding is specified utf8 is used\n         *\n         * @return String\n         */\n        readAsText: function (/**Object*/ entry, /**String=*/ encoding) {\n            var item = getEntry(entry);\n            if (item) {\n                var data = item.getData();\n                if (data && data.length) {\n                    return data.toString(encoding || \"utf8\");\n                }\n            }\n            return \"\";\n        },\n\n        /**\n         * Asynchronous readAsText\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param callback\n         * @param encoding Optional. If no encoding is specified utf8 is used\n         *\n         * @return String\n         */\n        readAsTextAsync: function (/**Object*/ entry, /**Function*/ callback, /**String=*/ encoding) {\n            var item = getEntry(entry);\n            if (item) {\n                item.getDataAsync(function (data, err) {\n                    if (err) {\n                        callback(data, err);\n                        return;\n                    }\n\n                    if (data && data.length) {\n                        callback(data.toString(encoding || \"utf8\"));\n                    } else {\n                        callback(\"\");\n                    }\n                });\n            } else {\n                callback(\"\");\n            }\n        },\n\n        /**\n         * Remove the entry from the file or the entry and all it's nested directories and files if the given entry is a directory\n         *\n         * @param entry\n         */\n        deleteFile: function (/**Object*/ entry) {\n            // @TODO: test deleteFile\n            var item = getEntry(entry);\n            if (item) {\n                _zip.deleteEntry(item.entryName);\n            }\n        },\n\n        /**\n         * Adds a comment to the zip. The zip must be rewritten after adding the comment.\n         *\n         * @param comment\n         */\n        addZipComment: function (/**String*/ comment) {\n            // @TODO: test addZipComment\n            _zip.comment = comment;\n        },\n\n        /**\n         * Returns the zip comment\n         *\n         * @return String\n         */\n        getZipComment: function () {\n            return _zip.comment || \"\";\n        },\n\n        /**\n         * Adds a comment to a specified zipEntry. The zip must be rewritten after adding the comment\n         * The comment cannot exceed 65535 characters in length\n         *\n         * @param entry\n         * @param comment\n         */\n        addZipEntryComment: function (/**Object*/ entry, /**String*/ comment) {\n            var item = getEntry(entry);\n            if (item) {\n                item.comment = comment;\n            }\n        },\n\n        /**\n         * Returns the comment of the specified entry\n         *\n         * @param entry\n         * @return String\n         */\n        getZipEntryComment: function (/**Object*/ entry) {\n            var item = getEntry(entry);\n            if (item) {\n                return item.comment || \"\";\n            }\n            return \"\";\n        },\n\n        /**\n         * Updates the content of an existing entry inside the archive. The zip must be rewritten after updating the content\n         *\n         * @param entry\n         * @param content\n         */\n        updateFile: function (/**Object*/ entry, /**Buffer*/ content) {\n            var item = getEntry(entry);\n            if (item) {\n                item.setData(content);\n            }\n        },\n\n        /**\n         * Adds a file from the disk to the archive\n         *\n         * @param localPath File to add to zip\n         * @param zipPath Optional path inside the zip\n         * @param zipName Optional name for the file\n         */\n        addLocalFile: function (/**String*/ localPath, /**String=*/ zipPath, /**String=*/ zipName, /**String*/ comment) {\n            if (filetools.fs.existsSync(localPath)) {\n                // fix ZipPath\n                zipPath = zipPath ? fixPath(zipPath) : \"\";\n\n                // p - local file name\n                var p = localPath.split(\"\\\\\").join(\"/\").split(\"/\").pop();\n\n                // add file name into zippath\n                zipPath += zipName ? zipName : p;\n\n                // read file attributes\n                const _attr = filetools.fs.statSync(localPath);\n\n                // add file into zip file\n                this.addFile(zipPath, filetools.fs.readFileSync(localPath), comment, _attr);\n            } else {\n                throw new Error(Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\n            }\n        },\n\n        /**\n         * Adds a local directory and all its nested files and directories to the archive\n         *\n         * @param localPath\n         * @param zipPath optional path inside zip\n         * @param filter optional RegExp or Function if files match will\n         *               be included.\n         * @param {number | object} attr - number as unix file permissions, object as filesystem Stats object\n         */\n        addLocalFolder: function (/**String*/ localPath, /**String=*/ zipPath, /**=RegExp|Function*/ filter, /**=number|object*/ attr) {\n            // Prepare filter\n            if (filter instanceof RegExp) {\n                // if filter is RegExp wrap it\n                filter = (function (rx) {\n                    return function (filename) {\n                        return rx.test(filename);\n                    };\n                })(filter);\n            } else if (\"function\" !== typeof filter) {\n                // if filter is not function we will replace it\n                filter = function () {\n                    return true;\n                };\n            }\n\n            // fix ZipPath\n            zipPath = zipPath ? fixPath(zipPath) : \"\";\n\n            // normalize the path first\n            localPath = pth.normalize(localPath);\n\n            if (filetools.fs.existsSync(localPath)) {\n                const items = filetools.findFiles(localPath);\n                const self = this;\n\n                if (items.length) {\n                    items.forEach(function (filepath) {\n                        var p = pth.relative(localPath, filepath).split(\"\\\\\").join(\"/\"); //windows fix\n                        if (filter(p)) {\n                            var stats = filetools.fs.statSync(filepath);\n                            if (stats.isFile()) {\n                                self.addFile(zipPath + p, filetools.fs.readFileSync(filepath), \"\", attr ? attr : stats);\n                            } else {\n                                self.addFile(zipPath + p + \"/\", Buffer.alloc(0), \"\", attr ? attr : stats);\n                            }\n                        }\n                    });\n                }\n            } else {\n                throw new Error(Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\n            }\n        },\n\n        /**\n         * Asynchronous addLocalFile\n         * @param localPath\n         * @param callback\n         * @param zipPath optional path inside zip\n         * @param filter optional RegExp or Function if files match will\n         *               be included.\n         */\n        addLocalFolderAsync: function (/*String*/ localPath, /*Function*/ callback, /*String*/ zipPath, /*RegExp|Function*/ filter) {\n            if (filter instanceof RegExp) {\n                filter = (function (rx) {\n                    return function (filename) {\n                        return rx.test(filename);\n                    };\n                })(filter);\n            } else if (\"function\" !== typeof filter) {\n                filter = function () {\n                    return true;\n                };\n            }\n\n            // fix ZipPath\n            zipPath = zipPath ? fixPath(zipPath) : \"\";\n\n            // normalize the path first\n            localPath = pth.normalize(localPath);\n\n            var self = this;\n            filetools.fs.open(localPath, \"r\", function (err) {\n                if (err && err.code === \"ENOENT\") {\n                    callback(undefined, Utils.Errors.FILE_NOT_FOUND.replace(\"%s\", localPath));\n                } else if (err) {\n                    callback(undefined, err);\n                } else {\n                    var items = filetools.findFiles(localPath);\n                    var i = -1;\n\n                    var next = function () {\n                        i += 1;\n                        if (i < items.length) {\n                            var filepath = items[i];\n                            var p = pth.relative(localPath, filepath).split(\"\\\\\").join(\"/\"); //windows fix\n                            p = p\n                                .normalize(\"NFD\")\n                                .replace(/[\\u0300-\\u036f]/g, \"\")\n                                .replace(/[^\\x20-\\x7E]/g, \"\"); // accent fix\n                            if (filter(p)) {\n                                filetools.fs.stat(filepath, function (er0, stats) {\n                                    if (er0) callback(undefined, er0);\n                                    if (stats.isFile()) {\n                                        filetools.fs.readFile(filepath, function (er1, data) {\n                                            if (er1) {\n                                                callback(undefined, er1);\n                                            } else {\n                                                self.addFile(zipPath + p, data, \"\", stats);\n                                                next();\n                                            }\n                                        });\n                                    } else {\n                                        self.addFile(zipPath + p + \"/\", Buffer.alloc(0), \"\", stats);\n                                        next();\n                                    }\n                                });\n                            } else {\n                                process.nextTick(() => {\n                                    next();\n                                });\n                            }\n                        } else {\n                            callback(true, undefined);\n                        }\n                    };\n\n                    next();\n                }\n            });\n        },\n\n        /**\n         *\n         * @param {string} localPath - path where files will be extracted\n         * @param {object} props - optional properties\n         * @param {string} props.zipPath - optional path inside zip\n         * @param {regexp, function} props.filter - RegExp or Function if files match will be included.\n         */\n        addLocalFolderPromise: function (/*String*/ localPath, /* object */ props) {\n            return new Promise((resolve, reject) => {\n                const { filter, zipPath } = Object.assign({}, props);\n                this.addLocalFolderAsync(\n                    localPath,\n                    (done, err) => {\n                        if (err) reject(err);\n                        if (done) resolve(this);\n                    },\n                    zipPath,\n                    filter\n                );\n            });\n        },\n\n        /**\n         * Allows you to create a entry (file or directory) in the zip file.\n         * If you want to create a directory the entryName must end in / and a null buffer should be provided.\n         * Comment and attributes are optional\n         *\n         * @param {string} entryName\n         * @param {Buffer | string} content - file content as buffer or utf8 coded string\n         * @param {string} comment - file comment\n         * @param {number | object} attr - number as unix file permissions, object as filesystem Stats object\n         */\n        addFile: function (/**String*/ entryName, /**Buffer*/ content, /**String*/ comment, /**Number*/ attr) {\n            let entry = getEntry(entryName);\n            const update = entry != null;\n\n            // prepare new entry\n            if (!update) {\n                entry = new ZipEntry();\n                entry.entryName = entryName;\n            }\n            entry.comment = comment || \"\";\n\n            const isStat = \"object\" === typeof attr && attr instanceof filetools.fs.Stats;\n\n            // last modification time from file stats\n            if (isStat) {\n                entry.header.time = attr.mtime;\n            }\n\n            // Set file attribute\n            var fileattr = entry.isDirectory ? 0x10 : 0; // (MS-DOS directory flag)\n\n            // extended attributes field for Unix\n            // set file type either S_IFDIR / S_IFREG\n            let unix = entry.isDirectory ? 0x4000 : 0x8000;\n\n            if (isStat) {\n                // File attributes from file stats\n                unix |= 0xfff & attr.mode;\n            } else if (\"number\" === typeof attr) {\n                // attr from given attr values\n                unix |= 0xfff & attr;\n            } else {\n                // Default values:\n                unix |= entry.isDirectory ? 0o755 : 0o644; // permissions (drwxr-xr-x) or (-r-wr--r--)\n            }\n\n            fileattr = (fileattr | (unix << 16)) >>> 0; // add attributes\n\n            entry.attr = fileattr;\n\n            entry.setData(content);\n            if (!update) _zip.setEntry(entry);\n        },\n\n        /**\n         * Returns an array of ZipEntry objects representing the files and folders inside the archive\n         *\n         * @return Array\n         */\n        getEntries: function () {\n            return _zip ? _zip.entries : [];\n        },\n\n        /**\n         * Returns a ZipEntry object representing the file or folder specified by ``name``.\n         *\n         * @param name\n         * @return ZipEntry\n         */\n        getEntry: function (/**String*/ name) {\n            return getEntry(name);\n        },\n\n        getEntryCount: function () {\n            return _zip.getEntryCount();\n        },\n\n        forEach: function (callback) {\n            return _zip.forEach(callback);\n        },\n\n        /**\n         * Extracts the given entry to the given targetPath\n         * If the entry is a directory inside the archive, the entire directory and it's subdirectories will be extracted\n         *\n         * @param entry ZipEntry object or String with the full path of the entry\n         * @param targetPath Target folder where to write the file\n         * @param maintainEntryPath If maintainEntryPath is true and the entry is inside a folder, the entry folder\n         *                          will be created in targetPath as well. Default is TRUE\n         * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\n         *                  Default is FALSE\n         * @param keepOriginalPermission The file will be set as the permission from the entry if this is true.\n         *                  Default is FALSE\n         * @param outFileName String If set will override the filename of the extracted file (Only works if the entry is a file)\n         *\n         * @return Boolean\n         */\n        extractEntryTo: function (\n            /**Object*/ entry,\n            /**String*/ targetPath,\n            /**Boolean*/ maintainEntryPath,\n            /**Boolean*/ overwrite,\n            /**Boolean*/ keepOriginalPermission,\n            /**String**/ outFileName\n        ) {\n            overwrite = get_Bool(overwrite, false);\n            keepOriginalPermission = get_Bool(keepOriginalPermission, false);\n            maintainEntryPath = get_Bool(maintainEntryPath, true);\n            outFileName = get_Str(outFileName, get_Str(keepOriginalPermission, undefined));\n\n            var item = getEntry(entry);\n            if (!item) {\n                throw new Error(Utils.Errors.NO_ENTRY);\n            }\n\n            var entryName = canonical(item.entryName);\n\n            var target = sanitize(targetPath, outFileName && !item.isDirectory ? outFileName : maintainEntryPath ? entryName : pth.basename(entryName));\n\n            if (item.isDirectory) {\n                var children = _zip.getEntryChildren(item);\n                children.forEach(function (child) {\n                    if (child.isDirectory) return;\n                    var content = child.getData();\n                    if (!content) {\n                        throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n                    }\n                    var name = canonical(child.entryName);\n                    var childName = sanitize(targetPath, maintainEntryPath ? name : pth.basename(name));\n                    // The reverse operation for attr depend on method addFile()\n                    const fileAttr = keepOriginalPermission ? child.header.fileAttr : undefined;\n                    filetools.writeFileTo(childName, content, overwrite, fileAttr);\n                });\n                return true;\n            }\n\n            var content = item.getData();\n            if (!content) throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n\n            if (filetools.fs.existsSync(target) && !overwrite) {\n                throw new Error(Utils.Errors.CANT_OVERRIDE);\n            }\n            // The reverse operation for attr depend on method addFile()\n            const fileAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n            filetools.writeFileTo(target, content, overwrite, fileAttr);\n\n            return true;\n        },\n\n        /**\n         * Test the archive\n         *\n         */\n        test: function (pass) {\n            if (!_zip) {\n                return false;\n            }\n\n            for (var entry in _zip.entries) {\n                try {\n                    if (entry.isDirectory) {\n                        continue;\n                    }\n                    var content = _zip.entries[entry].getData(pass);\n                    if (!content) {\n                        return false;\n                    }\n                } catch (err) {\n                    return false;\n                }\n            }\n            return true;\n        },\n\n        /**\n         * Extracts the entire archive to the given location\n         *\n         * @param targetPath Target location\n         * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\n         *                  Default is FALSE\n         * @param keepOriginalPermission The file will be set as the permission from the entry if this is true.\n         *                  Default is FALSE\n         */\n        extractAllTo: function (/**String*/ targetPath, /**Boolean*/ overwrite, /**Boolean*/ keepOriginalPermission, /*String, Buffer*/ pass) {\n            overwrite = get_Bool(overwrite, false);\n            pass = get_Str(keepOriginalPermission, pass);\n            keepOriginalPermission = get_Bool(keepOriginalPermission, false);\n            if (!_zip) {\n                throw new Error(Utils.Errors.NO_ZIP);\n            }\n            _zip.entries.forEach(function (entry) {\n                var entryName = sanitize(targetPath, canonical(entry.entryName.toString()));\n                if (entry.isDirectory) {\n                    filetools.makeDir(entryName);\n                    return;\n                }\n                var content = entry.getData(pass);\n                if (!content) {\n                    throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n                }\n                // The reverse operation for attr depend on method addFile()\n                const fileAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n                filetools.writeFileTo(entryName, content, overwrite, fileAttr);\n                try {\n                    filetools.fs.utimesSync(entryName, entry.header.time, entry.header.time);\n                } catch (err) {\n                    throw new Error(Utils.Errors.CANT_EXTRACT_FILE);\n                }\n            });\n        },\n\n        /**\n         * Asynchronous extractAllTo\n         *\n         * @param targetPath Target location\n         * @param overwrite If the file already exists at the target path, the file will be overwriten if this is true.\n         *                  Default is FALSE\n         * @param keepOriginalPermission The file will be set as the permission from the entry if this is true.\n         *                  Default is FALSE\n         * @param callback The callback will be executed when all entries are extracted successfully or any error is thrown.\n         */\n        extractAllToAsync: function (/**String*/ targetPath, /**Boolean*/ overwrite, /**Boolean*/ keepOriginalPermission, /**Function*/ callback) {\n            overwrite = get_Bool(overwrite, false);\n            if (typeof keepOriginalPermission === \"function\" && !callback) callback = keepOriginalPermission;\n            keepOriginalPermission = get_Bool(keepOriginalPermission, false);\n            if (!callback) {\n                callback = function (err) {\n                    throw new Error(err);\n                };\n            }\n            if (!_zip) {\n                callback(new Error(Utils.Errors.NO_ZIP));\n                return;\n            }\n\n            targetPath = pth.resolve(targetPath);\n            // convert entryName to\n            const getPath = (entry) => sanitize(targetPath, pth.normalize(canonical(entry.entryName.toString())));\n            const getError = (msg, file) => new Error(msg + ': \"' + file + '\"');\n\n            // separate directories from files\n            const dirEntries = [];\n            const fileEntries = new Set();\n            _zip.entries.forEach((e) => {\n                if (e.isDirectory) {\n                    dirEntries.push(e);\n                } else {\n                    fileEntries.add(e);\n                }\n            });\n\n            // Create directory entries first synchronously\n            // this prevents race condition and assures folders are there before writing files\n            for (const entry of dirEntries) {\n                const dirPath = getPath(entry);\n                // The reverse operation for attr depend on method addFile()\n                const dirAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n                try {\n                    filetools.makeDir(dirPath);\n                    if (dirAttr) filetools.fs.chmodSync(dirPath, dirAttr);\n                    // in unix timestamp will change if files are later added to folder, but still\n                    filetools.fs.utimesSync(dirPath, entry.header.time, entry.header.time);\n                } catch (er) {\n                    callback(getError(\"Unable to create folder\", dirPath));\n                }\n            }\n\n            // callback wrapper, for some house keeping\n            const done = () => {\n                if (fileEntries.size === 0) {\n                    callback();\n                }\n            };\n\n            // Extract file entries asynchronously\n            for (const entry of fileEntries.values()) {\n                const entryName = pth.normalize(canonical(entry.entryName.toString()));\n                const filePath = sanitize(targetPath, entryName);\n                entry.getDataAsync(function (content, err_1) {\n                    if (err_1) {\n                        callback(new Error(err_1));\n                        return;\n                    }\n                    if (!content) {\n                        callback(new Error(Utils.Errors.CANT_EXTRACT_FILE));\n                    } else {\n                        // The reverse operation for attr depend on method addFile()\n                        const fileAttr = keepOriginalPermission ? entry.header.fileAttr : undefined;\n                        filetools.writeFileToAsync(filePath, content, overwrite, fileAttr, function (succ) {\n                            if (!succ) {\n                                callback(getError(\"Unable to write file\", filePath));\n                                return;\n                            }\n                            filetools.fs.utimes(filePath, entry.header.time, entry.header.time, function (err_2) {\n                                if (err_2) {\n                                    callback(getError(\"Unable to set times\", filePath));\n                                    return;\n                                }\n                                fileEntries.delete(entry);\n                                // call the callback if it was last entry\n                                done();\n                            });\n                        });\n                    }\n                });\n            }\n            // call the callback if fileEntries was empty\n            done();\n        },\n\n        /**\n         * Writes the newly created zip file to disk at the specified location or if a zip was opened and no ``targetFileName`` is provided, it will overwrite the opened zip\n         *\n         * @param targetFileName\n         * @param callback\n         */\n        writeZip: function (/**String*/ targetFileName, /**Function*/ callback) {\n            if (arguments.length === 1) {\n                if (typeof targetFileName === \"function\") {\n                    callback = targetFileName;\n                    targetFileName = \"\";\n                }\n            }\n\n            if (!targetFileName && opts.filename) {\n                targetFileName = opts.filename;\n            }\n            if (!targetFileName) return;\n\n            var zipData = _zip.compressToBuffer();\n            if (zipData) {\n                var ok = filetools.writeFileTo(targetFileName, zipData, true);\n                if (typeof callback === \"function\") callback(!ok ? new Error(\"failed\") : null, \"\");\n            }\n        },\n\n        writeZipPromise: function (/**String*/ targetFileName, /* object */ props) {\n            const { overwrite, perm } = Object.assign({ overwrite: true }, props);\n\n            return new Promise((resolve, reject) => {\n                // find file name\n                if (!targetFileName && opts.filename) targetFileName = opts.filename;\n                if (!targetFileName) reject(\"ADM-ZIP: ZIP File Name Missing\");\n\n                this.toBufferPromise().then((zipData) => {\n                    const ret = (done) => (done ? resolve(done) : reject(\"ADM-ZIP: Wasn't able to write zip file\"));\n                    filetools.writeFileToAsync(targetFileName, zipData, overwrite, perm, ret);\n                }, reject);\n            });\n        },\n\n        toBufferPromise: function () {\n            return new Promise((resolve, reject) => {\n                _zip.toAsyncBuffer(resolve, reject);\n            });\n        },\n\n        /**\n         * Returns the content of the entire zip file as a Buffer object\n         *\n         * @return Buffer\n         */\n        toBuffer: function (/**Function=*/ onSuccess, /**Function=*/ onFail, /**Function=*/ onItemStart, /**Function=*/ onItemEnd) {\n            this.valueOf = 2;\n            if (typeof onSuccess === \"function\") {\n                _zip.toAsyncBuffer(onSuccess, onFail, onItemStart, onItemEnd);\n                return null;\n            }\n            return _zip.compressToBuffer();\n        }\n    };\n};\n","var Utils = require(\"../util\"),\n    Constants = Utils.Constants;\n\n/* The central directory file header */\nmodule.exports = function () {\n    var _verMade = 20, // v2.0\n        _version = 10, // v1.0\n        _flags = 0,\n        _method = 0,\n        _time = 0,\n        _crc = 0,\n        _compressedSize = 0,\n        _size = 0,\n        _fnameLen = 0,\n        _extraLen = 0,\n        _comLen = 0,\n        _diskStart = 0,\n        _inattr = 0,\n        _attr = 0,\n        _offset = 0;\n\n    _verMade |= Utils.isWin ? 0x0a00 : 0x0300;\n\n    // Set EFS flag since filename and comment fields are all by default encoded using UTF-8.\n    // Without it file names may be corrupted for other apps when file names use unicode chars\n    _flags |= Constants.FLG_EFS;\n\n    var _dataHeader = {};\n\n    function setTime(val) {\n        val = new Date(val);\n        _time =\n            (((val.getFullYear() - 1980) & 0x7f) << 25) | // b09-16 years from 1980\n            ((val.getMonth() + 1) << 21) | // b05-08 month\n            (val.getDate() << 16) | // b00-04 hour\n            // 2 bytes time\n            (val.getHours() << 11) | // b11-15 hour\n            (val.getMinutes() << 5) | // b05-10 minute\n            (val.getSeconds() >> 1); // b00-04 seconds divided by 2\n    }\n\n    setTime(+new Date());\n\n    return {\n        get made() {\n            return _verMade;\n        },\n        set made(val) {\n            _verMade = val;\n        },\n\n        get version() {\n            return _version;\n        },\n        set version(val) {\n            _version = val;\n        },\n\n        get flags() {\n            return _flags;\n        },\n        set flags(val) {\n            _flags = val;\n        },\n\n        get method() {\n            return _method;\n        },\n        set method(val) {\n            switch (val) {\n                case Constants.STORED:\n                    this.version = 10;\n                case Constants.DEFLATED:\n                default:\n                    this.version = 20;\n            }\n            _method = val;\n        },\n\n        get time() {\n            return new Date(((_time >> 25) & 0x7f) + 1980, ((_time >> 21) & 0x0f) - 1, (_time >> 16) & 0x1f, (_time >> 11) & 0x1f, (_time >> 5) & 0x3f, (_time & 0x1f) << 1);\n        },\n        set time(val) {\n            setTime(val);\n        },\n\n        get crc() {\n            return _crc;\n        },\n        set crc(val) {\n            _crc = Math.max(0, val) >>> 0;\n        },\n\n        get compressedSize() {\n            return _compressedSize;\n        },\n        set compressedSize(val) {\n            _compressedSize = Math.max(0, val) >>> 0;\n        },\n\n        get size() {\n            return _size;\n        },\n        set size(val) {\n            _size = Math.max(0, val) >>> 0;\n        },\n\n        get fileNameLength() {\n            return _fnameLen;\n        },\n        set fileNameLength(val) {\n            _fnameLen = val;\n        },\n\n        get extraLength() {\n            return _extraLen;\n        },\n        set extraLength(val) {\n            _extraLen = val;\n        },\n\n        get commentLength() {\n            return _comLen;\n        },\n        set commentLength(val) {\n            _comLen = val;\n        },\n\n        get diskNumStart() {\n            return _diskStart;\n        },\n        set diskNumStart(val) {\n            _diskStart = Math.max(0, val) >>> 0;\n        },\n\n        get inAttr() {\n            return _inattr;\n        },\n        set inAttr(val) {\n            _inattr = Math.max(0, val) >>> 0;\n        },\n\n        get attr() {\n            return _attr;\n        },\n        set attr(val) {\n            _attr = Math.max(0, val) >>> 0;\n        },\n\n        // get Unix file permissions\n        get fileAttr() {\n            return _attr ? (((_attr >>> 0) | 0) >> 16) & 0xfff : 0;\n        },\n\n        get offset() {\n            return _offset;\n        },\n        set offset(val) {\n            _offset = Math.max(0, val) >>> 0;\n        },\n\n        get encripted() {\n            return (_flags & 1) === 1;\n        },\n\n        get entryHeaderSize() {\n            return Constants.CENHDR + _fnameLen + _extraLen + _comLen;\n        },\n\n        get realDataOffset() {\n            return _offset + Constants.LOCHDR + _dataHeader.fnameLen + _dataHeader.extraLen;\n        },\n\n        get dataHeader() {\n            return _dataHeader;\n        },\n\n        loadDataHeaderFromBinary: function (/*Buffer*/ input) {\n            var data = input.slice(_offset, _offset + Constants.LOCHDR);\n            // 30 bytes and should start with \"PK\\003\\004\"\n            if (data.readUInt32LE(0) !== Constants.LOCSIG) {\n                throw new Error(Utils.Errors.INVALID_LOC);\n            }\n            _dataHeader = {\n                // version needed to extract\n                version: data.readUInt16LE(Constants.LOCVER),\n                // general purpose bit flag\n                flags: data.readUInt16LE(Constants.LOCFLG),\n                // compression method\n                method: data.readUInt16LE(Constants.LOCHOW),\n                // modification time (2 bytes time, 2 bytes date)\n                time: data.readUInt32LE(Constants.LOCTIM),\n                // uncompressed file crc-32 value\n                crc: data.readUInt32LE(Constants.LOCCRC),\n                // compressed size\n                compressedSize: data.readUInt32LE(Constants.LOCSIZ),\n                // uncompressed size\n                size: data.readUInt32LE(Constants.LOCLEN),\n                // filename length\n                fnameLen: data.readUInt16LE(Constants.LOCNAM),\n                // extra field length\n                extraLen: data.readUInt16LE(Constants.LOCEXT)\n            };\n        },\n\n        loadFromBinary: function (/*Buffer*/ data) {\n            // data should be 46 bytes and start with \"PK 01 02\"\n            if (data.length !== Constants.CENHDR || data.readUInt32LE(0) !== Constants.CENSIG) {\n                throw new Error(Utils.Errors.INVALID_CEN);\n            }\n            // version made by\n            _verMade = data.readUInt16LE(Constants.CENVEM);\n            // version needed to extract\n            _version = data.readUInt16LE(Constants.CENVER);\n            // encrypt, decrypt flags\n            _flags = data.readUInt16LE(Constants.CENFLG);\n            // compression method\n            _method = data.readUInt16LE(Constants.CENHOW);\n            // modification time (2 bytes time, 2 bytes date)\n            _time = data.readUInt32LE(Constants.CENTIM);\n            // uncompressed file crc-32 value\n            _crc = data.readUInt32LE(Constants.CENCRC);\n            // compressed size\n            _compressedSize = data.readUInt32LE(Constants.CENSIZ);\n            // uncompressed size\n            _size = data.readUInt32LE(Constants.CENLEN);\n            // filename length\n            _fnameLen = data.readUInt16LE(Constants.CENNAM);\n            // extra field length\n            _extraLen = data.readUInt16LE(Constants.CENEXT);\n            // file comment length\n            _comLen = data.readUInt16LE(Constants.CENCOM);\n            // volume number start\n            _diskStart = data.readUInt16LE(Constants.CENDSK);\n            // internal file attributes\n            _inattr = data.readUInt16LE(Constants.CENATT);\n            // external file attributes\n            _attr = data.readUInt32LE(Constants.CENATX);\n            // LOC header offset\n            _offset = data.readUInt32LE(Constants.CENOFF);\n        },\n\n        dataHeaderToBinary: function () {\n            // LOC header size (30 bytes)\n            var data = Buffer.alloc(Constants.LOCHDR);\n            // \"PK\\003\\004\"\n            data.writeUInt32LE(Constants.LOCSIG, 0);\n            // version needed to extract\n            data.writeUInt16LE(_version, Constants.LOCVER);\n            // general purpose bit flag\n            data.writeUInt16LE(_flags, Constants.LOCFLG);\n            // compression method\n            data.writeUInt16LE(_method, Constants.LOCHOW);\n            // modification time (2 bytes time, 2 bytes date)\n            data.writeUInt32LE(_time, Constants.LOCTIM);\n            // uncompressed file crc-32 value\n            data.writeUInt32LE(_crc, Constants.LOCCRC);\n            // compressed size\n            data.writeUInt32LE(_compressedSize, Constants.LOCSIZ);\n            // uncompressed size\n            data.writeUInt32LE(_size, Constants.LOCLEN);\n            // filename length\n            data.writeUInt16LE(_fnameLen, Constants.LOCNAM);\n            // extra field length\n            data.writeUInt16LE(_extraLen, Constants.LOCEXT);\n            return data;\n        },\n\n        entryHeaderToBinary: function () {\n            // CEN header size (46 bytes)\n            var data = Buffer.alloc(Constants.CENHDR + _fnameLen + _extraLen + _comLen);\n            // \"PK\\001\\002\"\n            data.writeUInt32LE(Constants.CENSIG, 0);\n            // version made by\n            data.writeUInt16LE(_verMade, Constants.CENVEM);\n            // version needed to extract\n            data.writeUInt16LE(_version, Constants.CENVER);\n            // encrypt, decrypt flags\n            data.writeUInt16LE(_flags, Constants.CENFLG);\n            // compression method\n            data.writeUInt16LE(_method, Constants.CENHOW);\n            // modification time (2 bytes time, 2 bytes date)\n            data.writeUInt32LE(_time, Constants.CENTIM);\n            // uncompressed file crc-32 value\n            data.writeUInt32LE(_crc, Constants.CENCRC);\n            // compressed size\n            data.writeUInt32LE(_compressedSize, Constants.CENSIZ);\n            // uncompressed size\n            data.writeUInt32LE(_size, Constants.CENLEN);\n            // filename length\n            data.writeUInt16LE(_fnameLen, Constants.CENNAM);\n            // extra field length\n            data.writeUInt16LE(_extraLen, Constants.CENEXT);\n            // file comment length\n            data.writeUInt16LE(_comLen, Constants.CENCOM);\n            // volume number start\n            data.writeUInt16LE(_diskStart, Constants.CENDSK);\n            // internal file attributes\n            data.writeUInt16LE(_inattr, Constants.CENATT);\n            // external file attributes\n            data.writeUInt32LE(_attr, Constants.CENATX);\n            // LOC header offset\n            data.writeUInt32LE(_offset, Constants.CENOFF);\n            // fill all with\n            data.fill(0x00, Constants.CENHDR);\n            return data;\n        },\n\n        toJSON: function () {\n            const bytes = function (nr) {\n                return nr + \" bytes\";\n            };\n\n            return {\n                made: _verMade,\n                version: _version,\n                flags: _flags,\n                method: Utils.methodToString(_method),\n                time: this.time,\n                crc: \"0x\" + _crc.toString(16).toUpperCase(),\n                compressedSize: bytes(_compressedSize),\n                size: bytes(_size),\n                fileNameLength: bytes(_fnameLen),\n                extraLength: bytes(_extraLen),\n                commentLength: bytes(_comLen),\n                diskNumStart: _diskStart,\n                inAttr: _inattr,\n                attr: _attr,\n                offset: _offset,\n                entryHeaderSize: bytes(Constants.CENHDR + _fnameLen + _extraLen + _comLen)\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","exports.EntryHeader = require(\"./entryHeader\");\nexports.MainHeader = require(\"./mainHeader\");\n","var Utils = require(\"../util\"),\n    Constants = Utils.Constants;\n\n/* The entries in the end of central directory */\nmodule.exports = function () {\n    var _volumeEntries = 0,\n        _totalEntries = 0,\n        _size = 0,\n        _offset = 0,\n        _commentLength = 0;\n\n    return {\n        get diskEntries() {\n            return _volumeEntries;\n        },\n        set diskEntries(/*Number*/ val) {\n            _volumeEntries = _totalEntries = val;\n        },\n\n        get totalEntries() {\n            return _totalEntries;\n        },\n        set totalEntries(/*Number*/ val) {\n            _totalEntries = _volumeEntries = val;\n        },\n\n        get size() {\n            return _size;\n        },\n        set size(/*Number*/ val) {\n            _size = val;\n        },\n\n        get offset() {\n            return _offset;\n        },\n        set offset(/*Number*/ val) {\n            _offset = val;\n        },\n\n        get commentLength() {\n            return _commentLength;\n        },\n        set commentLength(/*Number*/ val) {\n            _commentLength = val;\n        },\n\n        get mainHeaderSize() {\n            return Constants.ENDHDR + _commentLength;\n        },\n\n        loadFromBinary: function (/*Buffer*/ data) {\n            // data should be 22 bytes and start with \"PK 05 06\"\n            // or be 56+ bytes and start with \"PK 06 06\" for Zip64\n            if (\n                (data.length !== Constants.ENDHDR || data.readUInt32LE(0) !== Constants.ENDSIG) &&\n                (data.length < Constants.ZIP64HDR || data.readUInt32LE(0) !== Constants.ZIP64SIG)\n            ) {\n                throw new Error(Utils.Errors.INVALID_END);\n            }\n\n            if (data.readUInt32LE(0) === Constants.ENDSIG) {\n                // number of entries on this volume\n                _volumeEntries = data.readUInt16LE(Constants.ENDSUB);\n                // total number of entries\n                _totalEntries = data.readUInt16LE(Constants.ENDTOT);\n                // central directory size in bytes\n                _size = data.readUInt32LE(Constants.ENDSIZ);\n                // offset of first CEN header\n                _offset = data.readUInt32LE(Constants.ENDOFF);\n                // zip file comment length\n                _commentLength = data.readUInt16LE(Constants.ENDCOM);\n            } else {\n                // number of entries on this volume\n                _volumeEntries = Utils.readBigUInt64LE(data, Constants.ZIP64SUB);\n                // total number of entries\n                _totalEntries = Utils.readBigUInt64LE(data, Constants.ZIP64TOT);\n                // central directory size in bytes\n                _size = Utils.readBigUInt64LE(data, Constants.ZIP64SIZE);\n                // offset of first CEN header\n                _offset = Utils.readBigUInt64LE(data, Constants.ZIP64OFF);\n\n                _commentLength = 0;\n            }\n        },\n\n        toBinary: function () {\n            var b = Buffer.alloc(Constants.ENDHDR + _commentLength);\n            // \"PK 05 06\" signature\n            b.writeUInt32LE(Constants.ENDSIG, 0);\n            b.writeUInt32LE(0, 4);\n            // number of entries on this volume\n            b.writeUInt16LE(_volumeEntries, Constants.ENDSUB);\n            // total number of entries\n            b.writeUInt16LE(_totalEntries, Constants.ENDTOT);\n            // central directory size in bytes\n            b.writeUInt32LE(_size, Constants.ENDSIZ);\n            // offset of first CEN header\n            b.writeUInt32LE(_offset, Constants.ENDOFF);\n            // zip file comment length\n            b.writeUInt16LE(_commentLength, Constants.ENDCOM);\n            // fill comment memory with spaces so no garbage is left there\n            b.fill(\" \", Constants.ENDHDR);\n\n            return b;\n        },\n\n        toJSON: function () {\n            // creates 0x0000 style output\n            const offset = function (nr, len) {\n                let offs = nr.toString(16).toUpperCase();\n                while (offs.length < len) offs = \"0\" + offs;\n                return \"0x\" + offs;\n            };\n\n            return {\n                diskEntries: _volumeEntries,\n                totalEntries: _totalEntries,\n                size: _size + \" bytes\",\n                offset: offset(_offset, 4),\n                commentLength: _commentLength\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n // Misspelled ","module.exports = function (/*Buffer*/ inbuf) {\n    var zlib = require(\"zlib\");\n\n    var opts = { chunkSize: (parseInt(inbuf.length / 1024) + 1) * 1024 };\n\n    return {\n        deflate: function () {\n            return zlib.deflateRawSync(inbuf, opts);\n        },\n\n        deflateAsync: function (/*Function*/ callback) {\n            var tmp = zlib.createDeflateRaw(opts),\n                parts = [],\n                total = 0;\n            tmp.on(\"data\", function (data) {\n                parts.push(data);\n                total += data.length;\n            });\n            tmp.on(\"end\", function () {\n                var buf = Buffer.alloc(total),\n                    written = 0;\n                buf.fill(0);\n                for (var i = 0; i < parts.length; i++) {\n                    var part = parts[i];\n                    part.copy(buf, written);\n                    written += part.length;\n                }\n                callback && callback(buf);\n            });\n            tmp.end(inbuf);\n        }\n    };\n};\n","exports.Deflater = require(\"./deflater\");\nexports.Inflater = require(\"./inflater\");\nexports.ZipCrypto = require(\"./zipcrypto\");\n","module.exports = function (/*Buffer*/ inbuf) {\n    var zlib = require(\"zlib\");\n\n    return {\n        inflate: function () {\n            return zlib.inflateRawSync(inbuf);\n        },\n\n        inflateAsync: function (/*Function*/ callback) {\n            var tmp = zlib.createInflateRaw(),\n                parts = [],\n                total = 0;\n            tmp.on(\"data\", function (data) {\n                parts.push(data);\n                total += data.length;\n            });\n            tmp.on(\"end\", function () {\n                var buf = Buffer.alloc(total),\n                    written = 0;\n                buf.fill(0);\n                for (var i = 0; i < parts.length; i++) {\n                    var part = parts[i];\n                    part.copy(buf, written);\n                    written += part.length;\n                }\n                callback && callback(buf);\n            });\n            tmp.end(inbuf);\n        }\n    };\n};\n","\"use strict\";\n\n// node crypt, we use it for generate salt\n// eslint-disable-next-line node/no-unsupported-features/node-builtins\nconst { randomFillSync } = require(\"crypto\");\n\n// generate CRC32 lookup table\nconst crctable = new Uint32Array(256).map((t, crc) => {\n    for (let j = 0; j < 8; j++) {\n        if (0 !== (crc & 1)) {\n            crc = (crc >>> 1) ^ 0xedb88320;\n        } else {\n            crc >>>= 1;\n        }\n    }\n    return crc >>> 0;\n});\n\n// C-style uInt32 Multiply (discards higher bits, when JS multiply discards lower bits)\nconst uMul = (a, b) => Math.imul(a, b) >>> 0;\n\n// crc32 byte single update (actually same function is part of utils.crc32 function :) )\nconst crc32update = (pCrc32, bval) => {\n    return crctable[(pCrc32 ^ bval) & 0xff] ^ (pCrc32 >>> 8);\n};\n\n// function for generating salt for encrytion header\nconst genSalt = () => {\n    if (\"function\" === typeof randomFillSync) {\n        return randomFillSync(Buffer.alloc(12));\n    } else {\n        // fallback if function is not defined\n        return genSalt.node();\n    }\n};\n\n// salt generation with node random function (mainly as fallback)\ngenSalt.node = () => {\n    const salt = Buffer.alloc(12);\n    const len = salt.length;\n    for (let i = 0; i < len; i++) salt[i] = (Math.random() * 256) & 0xff;\n    return salt;\n};\n\n// general config\nconst config = {\n    genSalt\n};\n\n// Class Initkeys handles same basic ops with keys\nfunction Initkeys(pw) {\n    const pass = Buffer.isBuffer(pw) ? pw : Buffer.from(pw);\n    this.keys = new Uint32Array([0x12345678, 0x23456789, 0x34567890]);\n    for (let i = 0; i < pass.length; i++) {\n        this.updateKeys(pass[i]);\n    }\n}\n\nInitkeys.prototype.updateKeys = function (byteValue) {\n    const keys = this.keys;\n    keys[0] = crc32update(keys[0], byteValue);\n    keys[1] += keys[0] & 0xff;\n    keys[1] = uMul(keys[1], 134775813) + 1;\n    keys[2] = crc32update(keys[2], keys[1] >>> 24);\n    return byteValue;\n};\n\nInitkeys.prototype.next = function () {\n    const k = (this.keys[2] | 2) >>> 0; // key\n    return (uMul(k, k ^ 1) >> 8) & 0xff; // decode\n};\n\nfunction make_decrypter(/*Buffer*/ pwd) {\n    // 1. Stage initialize key\n    const keys = new Initkeys(pwd);\n\n    // return decrypter function\n    return function (/*Buffer*/ data) {\n        // result - we create new Buffer for results\n        const result = Buffer.alloc(data.length);\n        let pos = 0;\n        // process input data\n        for (let c of data) {\n            //c ^= keys.next();\n            //result[pos++] = c; // decode & Save Value\n            result[pos++] = keys.updateKeys(c ^ keys.next()); // update keys with decoded byte\n        }\n        return result;\n    };\n}\n\nfunction make_encrypter(/*Buffer*/ pwd) {\n    // 1. Stage initialize key\n    const keys = new Initkeys(pwd);\n\n    // return encrypting function, result and pos is here so we dont have to merge buffers later\n    return function (/*Buffer*/ data, /*Buffer*/ result, /* Number */ pos = 0) {\n        // result - we create new Buffer for results\n        if (!result) result = Buffer.alloc(data.length);\n        // process input data\n        for (let c of data) {\n            const k = keys.next(); // save key byte\n            result[pos++] = c ^ k; // save val\n            keys.updateKeys(c); // update keys with decoded byte\n        }\n        return result;\n    };\n}\n\nfunction decrypt(/*Buffer*/ data, /*Object*/ header, /*String, Buffer*/ pwd) {\n    if (!data || !Buffer.isBuffer(data) || data.length < 12) {\n        return Buffer.alloc(0);\n    }\n\n    // 1. We Initialize and generate decrypting function\n    const decrypter = make_decrypter(pwd);\n\n    // 2. decrypt salt what is always 12 bytes and is a part of file content\n    const salt = decrypter(data.slice(0, 12));\n\n    // 3. does password meet expectations\n    if (salt[11] !== header.crc >>> 24) {\n        throw \"ADM-ZIP: Wrong Password\";\n    }\n\n    // 4. decode content\n    return decrypter(data.slice(12));\n}\n\n// lets add way to populate salt, NOT RECOMMENDED for production but maybe useful for testing general functionality\nfunction _salter(data) {\n    if (Buffer.isBuffer(data) && data.length >= 12) {\n        // be aware - currently salting buffer data is modified\n        config.genSalt = function () {\n            return data.slice(0, 12);\n        };\n    } else if (data === \"node\") {\n        // test salt generation with node random function\n        config.genSalt = genSalt.node;\n    } else {\n        // if value is not acceptable config gets reset.\n        config.genSalt = genSalt;\n    }\n}\n\nfunction encrypt(/*Buffer*/ data, /*Object*/ header, /*String, Buffer*/ pwd, /*Boolean*/ oldlike = false) {\n    // 1. test data if data is not Buffer we make buffer from it\n    if (data == null) data = Buffer.alloc(0);\n    // if data is not buffer be make buffer from it\n    if (!Buffer.isBuffer(data)) data = Buffer.from(data.toString());\n\n    // 2. We Initialize and generate encrypting function\n    const encrypter = make_encrypter(pwd);\n\n    // 3. generate salt (12-bytes of random data)\n    const salt = config.genSalt();\n    salt[11] = (header.crc >>> 24) & 0xff;\n\n    // old implementations (before PKZip 2.04g) used two byte check\n    if (oldlike) salt[10] = (header.crc >>> 16) & 0xff;\n\n    // 4. create output\n    const result = Buffer.alloc(data.length + 12);\n    encrypter(salt, result);\n\n    // finally encode content\n    return encrypter(data, result, 12);\n}\n\nmodule.exports = { decrypt, encrypt, _salter };\n","module.exports = {\n    /* The local file header */\n    LOCHDR           : 30, // LOC header size\n    LOCSIG           : 0x04034b50, // \"PK\\003\\004\"\n    LOCVER           : 4,\t// version needed to extract\n    LOCFLG           : 6, // general purpose bit flag\n    LOCHOW           : 8, // compression method\n    LOCTIM           : 10, // modification time (2 bytes time, 2 bytes date)\n    LOCCRC           : 14, // uncompressed file crc-32 value\n    LOCSIZ           : 18, // compressed size\n    LOCLEN           : 22, // uncompressed size\n    LOCNAM           : 26, // filename length\n    LOCEXT           : 28, // extra field length\n\n    /* The Data descriptor */\n    EXTSIG           : 0x08074b50, // \"PK\\007\\008\"\n    EXTHDR           : 16, // EXT header size\n    EXTCRC           : 4, // uncompressed file crc-32 value\n    EXTSIZ           : 8, // compressed size\n    EXTLEN           : 12, // uncompressed size\n\n    /* The central directory file header */\n    CENHDR           : 46, // CEN header size\n    CENSIG           : 0x02014b50, // \"PK\\001\\002\"\n    CENVEM           : 4, // version made by\n    CENVER           : 6, // version needed to extract\n    CENFLG           : 8, // encrypt, decrypt flags\n    CENHOW           : 10, // compression method\n    CENTIM           : 12, // modification time (2 bytes time, 2 bytes date)\n    CENCRC           : 16, // uncompressed file crc-32 value\n    CENSIZ           : 20, // compressed size\n    CENLEN           : 24, // uncompressed size\n    CENNAM           : 28, // filename length\n    CENEXT           : 30, // extra field length\n    CENCOM           : 32, // file comment length\n    CENDSK           : 34, // volume number start\n    CENATT           : 36, // internal file attributes\n    CENATX           : 38, // external file attributes (host system dependent)\n    CENOFF           : 42, // LOC header offset\n\n    /* The entries in the end of central directory */\n    ENDHDR           : 22, // END header size\n    ENDSIG           : 0x06054b50, // \"PK\\005\\006\"\n    ENDSUB           : 8, // number of entries on this disk\n    ENDTOT           : 10, // total number of entries\n    ENDSIZ           : 12, // central directory size in bytes\n    ENDOFF           : 16, // offset of first CEN header\n    ENDCOM           : 20, // zip file comment length\n\n    END64HDR         : 20, // zip64 END header size\n    END64SIG         : 0x07064b50, // zip64 Locator signature, \"PK\\006\\007\"\n    END64START       : 4, // number of the disk with the start of the zip64\n    END64OFF         : 8, // relative offset of the zip64 end of central directory\n    END64NUMDISKS    : 16, // total number of disks\n\n    ZIP64SIG         : 0x06064b50, // zip64 signature, \"PK\\006\\006\"\n    ZIP64HDR         : 56, // zip64 record minimum size\n    ZIP64LEAD        : 12, // leading bytes at the start of the record, not counted by the value stored in ZIP64SIZE\n    ZIP64SIZE        : 4, // zip64 size of the central directory record\n    ZIP64VEM         : 12, // zip64 version made by\n    ZIP64VER         : 14, // zip64 version needed to extract\n    ZIP64DSK         : 16, // zip64 number of this disk\n    ZIP64DSKDIR      : 20, // number of the disk with the start of the record directory\n    ZIP64SUB         : 24, // number of entries on this disk\n    ZIP64TOT         : 32, // total number of entries\n    ZIP64SIZB        : 40, // zip64 central directory size in bytes\n    ZIP64OFF         : 48, // offset of start of central directory with respect to the starting disk number\n    ZIP64EXTRA       : 56, // extensible data sector\n\n    /* Compression methods */\n    STORED           : 0, // no compression\n    SHRUNK           : 1, // shrunk\n    REDUCED1         : 2, // reduced with compression factor 1\n    REDUCED2         : 3, // reduced with compression factor 2\n    REDUCED3         : 4, // reduced with compression factor 3\n    REDUCED4         : 5, // reduced with compression factor 4\n    IMPLODED         : 6, // imploded\n    // 7 reserved for Tokenizing compression algorithm\n    DEFLATED         : 8, // deflated\n    ENHANCED_DEFLATED: 9, // enhanced deflated\n    PKWARE           : 10,// PKWare DCL imploded\n    // 11 reserved by PKWARE\n    BZIP2            : 12, //  compressed using BZIP2\n    // 13 reserved by PKWARE\n    LZMA             : 14, // LZMA\n    // 15-17 reserved by PKWARE\n    IBM_TERSE        : 18, // compressed using IBM TERSE\n    IBM_LZ77         : 19, // IBM LZ77 z\n    AES_ENCRYPT      : 99, // WinZIP AES encryption method\n\n    /* General purpose bit flag */\n    // values can obtained with expression 2**bitnr\n    FLG_ENC          : 1,    // Bit 0: encrypted file\n    FLG_COMP1        : 2,    // Bit 1, compression option\n    FLG_COMP2        : 4,    // Bit 2, compression option\n    FLG_DESC         : 8,    // Bit 3, data descriptor\n    FLG_ENH          : 16,   // Bit 4, enhanced deflating\n    FLG_PATCH        : 32,   // Bit 5, indicates that the file is compressed patched data.\n    FLG_STR          : 64,   // Bit 6, strong encryption (patented)\n                             // Bits 7-10: Currently unused.\n    FLG_EFS          : 2048, // Bit 11: Language encoding flag (EFS)\n                             // Bit 12: Reserved by PKWARE for enhanced compression.\n                             // Bit 13: encrypted the Central Directory (patented).\n                             // Bits 14-15: Reserved by PKWARE.\n    FLG_MSK          : 4096, // mask header values\n\n    /* Load type */\n    FILE             : 2,\n    BUFFER           : 1,\n    NONE             : 0,\n\n    /* 4.5 Extensible data fields */\n    EF_ID            : 0,\n    EF_SIZE          : 2,\n\n    /* Header IDs */\n    ID_ZIP64         : 0x0001,\n    ID_AVINFO        : 0x0007,\n    ID_PFS           : 0x0008,\n    ID_OS2           : 0x0009,\n    ID_NTFS          : 0x000a,\n    ID_OPENVMS       : 0x000c,\n    ID_UNIX          : 0x000d,\n    ID_FORK          : 0x000e,\n    ID_PATCH         : 0x000f,\n    ID_X509_PKCS7    : 0x0014,\n    ID_X509_CERTID_F : 0x0015,\n    ID_X509_CERTID_C : 0x0016,\n    ID_STRONGENC     : 0x0017,\n    ID_RECORD_MGT    : 0x0018,\n    ID_X509_PKCS7_RL : 0x0019,\n    ID_IBM1          : 0x0065,\n    ID_IBM2          : 0x0066,\n    ID_POSZIP        : 0x4690,\n\n    EF_ZIP64_OR_32   : 0xffffffff,\n    EF_ZIP64_OR_16   : 0xffff,\n    EF_ZIP64_SUNCOMP : 0,\n    EF_ZIP64_SCOMP   : 8,\n    EF_ZIP64_RHO     : 16,\n    EF_ZIP64_DSN     : 24\n};\n","module.exports = {\n    /* Header error messages */\n    INVALID_LOC: \"Invalid LOC header (bad signature)\",\n    INVALID_CEN: \"Invalid CEN header (bad signature)\",\n    INVALID_END: \"Invalid END header (bad signature)\",\n\n    /* ZipEntry error messages*/\n    NO_DATA: \"Nothing to decompress\",\n    BAD_CRC: \"CRC32 checksum failed\",\n    FILE_IN_THE_WAY: \"There is a file in the way: %s\",\n    UNKNOWN_METHOD: \"Invalid/unsupported compression method\",\n\n    /* Inflater error messages */\n    AVAIL_DATA: \"inflate::Available inflate data did not terminate\",\n    INVALID_DISTANCE: \"inflate::Invalid literal/length or distance code in fixed or dynamic block\",\n    TO_MANY_CODES: \"inflate::Dynamic block code description: too many length or distance codes\",\n    INVALID_REPEAT_LEN: \"inflate::Dynamic block code description: repeat more than specified lengths\",\n    INVALID_REPEAT_FIRST: \"inflate::Dynamic block code description: repeat lengths with no first length\",\n    INCOMPLETE_CODES: \"inflate::Dynamic block code description: code lengths codes incomplete\",\n    INVALID_DYN_DISTANCE: \"inflate::Dynamic block code description: invalid distance code lengths\",\n    INVALID_CODES_LEN: \"inflate::Dynamic block code description: invalid literal/length code lengths\",\n    INVALID_STORE_BLOCK: \"inflate::Stored block length did not match one's complement\",\n    INVALID_BLOCK_TYPE: \"inflate::Invalid block type (type == 3)\",\n\n    /* ADM-ZIP error messages */\n    CANT_EXTRACT_FILE: \"Could not extract the file\",\n    CANT_OVERRIDE: \"Target file already exists\",\n    NO_ZIP: \"No zip file was loaded\",\n    NO_ENTRY: \"Entry doesn't exist\",\n    DIRECTORY_CONTENT_ERROR: \"A directory cannot have content\",\n    FILE_NOT_FOUND: \"File not found: %s\",\n    NOT_IMPLEMENTED: \"Not implemented\",\n    INVALID_FILENAME: \"Invalid filename\",\n    INVALID_FORMAT: \"Invalid or unsupported zip format. No END header found\"\n};\n","const fs = require(\"./fileSystem\").require();\nconst pth = require(\"path\");\n\nfs.existsSync = fs.existsSync || pth.existsSync;\n\nmodule.exports = function (/*String*/ path) {\n    var _path = path || \"\",\n        _obj = newAttr(),\n        _stat = null;\n\n    function newAttr() {\n        return {\n            directory: false,\n            readonly: false,\n            hidden: false,\n            executable: false,\n            mtime: 0,\n            atime: 0\n        };\n    }\n\n    if (_path && fs.existsSync(_path)) {\n        _stat = fs.statSync(_path);\n        _obj.directory = _stat.isDirectory();\n        _obj.mtime = _stat.mtime;\n        _obj.atime = _stat.atime;\n        _obj.executable = (0o111 & _stat.mode) !== 0; // file is executable who ever har right not just owner\n        _obj.readonly = (0o200 & _stat.mode) === 0; // readonly if owner has no write right\n        _obj.hidden = pth.basename(_path)[0] === \".\";\n    } else {\n        console.warn(\"Invalid path: \" + _path);\n    }\n\n    return {\n        get directory() {\n            return _obj.directory;\n        },\n\n        get readOnly() {\n            return _obj.readonly;\n        },\n\n        get hidden() {\n            return _obj.hidden;\n        },\n\n        get mtime() {\n            return _obj.mtime;\n        },\n\n        get atime() {\n            return _obj.atime;\n        },\n\n        get executable() {\n            return _obj.executable;\n        },\n\n        decodeAttributes: function () {},\n\n        encodeAttributes: function () {},\n\n        toJSON: function () {\n            return {\n                path: _path,\n                isDirectory: _obj.directory,\n                isReadOnly: _obj.readonly,\n                isHidden: _obj.hidden,\n                isExecutable: _obj.executable,\n                mTime: _obj.mtime,\n                aTime: _obj.atime\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","exports.require = function () {\n    if (typeof process === \"object\" && process.versions && process.versions[\"electron\"]) {\n        try {\n            const originalFs = require(\"original-fs\");\n            if (Object.keys(originalFs).length > 0) {\n                return originalFs;\n            }\n        } catch (e) {}\n    }\n    return require(\"fs\");\n};\n","module.exports = require(\"./utils\");\nmodule.exports.Constants = require(\"./constants\");\nmodule.exports.Errors = require(\"./errors\");\nmodule.exports.FileAttr = require(\"./fattr\");\n","const fsystem = require(\"./fileSystem\").require();\nconst pth = require(\"path\");\nconst Constants = require(\"./constants\");\nconst Errors = require(\"./errors\");\nconst isWin = typeof process === \"object\" && \"win32\" === process.platform;\n\nconst is_Obj = (obj) => obj && typeof obj === \"object\";\n\n// generate CRC32 lookup table\nconst crcTable = new Uint32Array(256).map((t, c) => {\n    for (let k = 0; k < 8; k++) {\n        if ((c & 1) !== 0) {\n            c = 0xedb88320 ^ (c >>> 1);\n        } else {\n            c >>>= 1;\n        }\n    }\n    return c >>> 0;\n});\n\n// UTILS functions\n\nfunction Utils(opts) {\n    this.sep = pth.sep;\n    this.fs = fsystem;\n\n    if (is_Obj(opts)) {\n        // custom filesystem\n        if (is_Obj(opts.fs) && typeof opts.fs.statSync === \"function\") {\n            this.fs = opts.fs;\n        }\n    }\n}\n\nmodule.exports = Utils;\n\n// INSTANCED functions\n\nUtils.prototype.makeDir = function (/*String*/ folder) {\n    const self = this;\n\n    // Sync - make directories tree\n    function mkdirSync(/*String*/ fpath) {\n        let resolvedPath = fpath.split(self.sep)[0];\n        fpath.split(self.sep).forEach(function (name) {\n            if (!name || name.substr(-1, 1) === \":\") return;\n            resolvedPath += self.sep + name;\n            var stat;\n            try {\n                stat = self.fs.statSync(resolvedPath);\n            } catch (e) {\n                self.fs.mkdirSync(resolvedPath);\n            }\n            if (stat && stat.isFile()) throw Errors.FILE_IN_THE_WAY.replace(\"%s\", resolvedPath);\n        });\n    }\n\n    mkdirSync(folder);\n};\n\nUtils.prototype.writeFileTo = function (/*String*/ path, /*Buffer*/ content, /*Boolean*/ overwrite, /*Number*/ attr) {\n    const self = this;\n    if (self.fs.existsSync(path)) {\n        if (!overwrite) return false; // cannot overwrite\n\n        var stat = self.fs.statSync(path);\n        if (stat.isDirectory()) {\n            return false;\n        }\n    }\n    var folder = pth.dirname(path);\n    if (!self.fs.existsSync(folder)) {\n        self.makeDir(folder);\n    }\n\n    var fd;\n    try {\n        fd = self.fs.openSync(path, \"w\", 438); // 0666\n    } catch (e) {\n        self.fs.chmodSync(path, 438);\n        fd = self.fs.openSync(path, \"w\", 438);\n    }\n    if (fd) {\n        try {\n            self.fs.writeSync(fd, content, 0, content.length, 0);\n        } finally {\n            self.fs.closeSync(fd);\n        }\n    }\n    self.fs.chmodSync(path, attr || 438);\n    return true;\n};\n\nUtils.prototype.writeFileToAsync = function (/*String*/ path, /*Buffer*/ content, /*Boolean*/ overwrite, /*Number*/ attr, /*Function*/ callback) {\n    if (typeof attr === \"function\") {\n        callback = attr;\n        attr = undefined;\n    }\n\n    const self = this;\n\n    self.fs.exists(path, function (exist) {\n        if (exist && !overwrite) return callback(false);\n\n        self.fs.stat(path, function (err, stat) {\n            if (exist && stat.isDirectory()) {\n                return callback(false);\n            }\n\n            var folder = pth.dirname(path);\n            self.fs.exists(folder, function (exists) {\n                if (!exists) self.makeDir(folder);\n\n                self.fs.open(path, \"w\", 438, function (err, fd) {\n                    if (err) {\n                        self.fs.chmod(path, 438, function () {\n                            self.fs.open(path, \"w\", 438, function (err, fd) {\n                                self.fs.write(fd, content, 0, content.length, 0, function () {\n                                    self.fs.close(fd, function () {\n                                        self.fs.chmod(path, attr || 438, function () {\n                                            callback(true);\n                                        });\n                                    });\n                                });\n                            });\n                        });\n                    } else if (fd) {\n                        self.fs.write(fd, content, 0, content.length, 0, function () {\n                            self.fs.close(fd, function () {\n                                self.fs.chmod(path, attr || 438, function () {\n                                    callback(true);\n                                });\n                            });\n                        });\n                    } else {\n                        self.fs.chmod(path, attr || 438, function () {\n                            callback(true);\n                        });\n                    }\n                });\n            });\n        });\n    });\n};\n\nUtils.prototype.findFiles = function (/*String*/ path) {\n    const self = this;\n\n    function findSync(/*String*/ dir, /*RegExp*/ pattern, /*Boolean*/ recursive) {\n        if (typeof pattern === \"boolean\") {\n            recursive = pattern;\n            pattern = undefined;\n        }\n        let files = [];\n        self.fs.readdirSync(dir).forEach(function (file) {\n            var path = pth.join(dir, file);\n\n            if (self.fs.statSync(path).isDirectory() && recursive) files = files.concat(findSync(path, pattern, recursive));\n\n            if (!pattern || pattern.test(path)) {\n                files.push(pth.normalize(path) + (self.fs.statSync(path).isDirectory() ? self.sep : \"\"));\n            }\n        });\n        return files;\n    }\n\n    return findSync(path, undefined, true);\n};\n\nUtils.prototype.getAttributes = function () {};\n\nUtils.prototype.setAttributes = function () {};\n\n// STATIC functions\n\n// crc32 single update (it is part of crc32)\nUtils.crc32update = function (crc, byte) {\n    return crcTable[(crc ^ byte) & 0xff] ^ (crc >>> 8);\n};\n\nUtils.crc32 = function (buf) {\n    if (typeof buf === \"string\") {\n        buf = Buffer.from(buf, \"utf8\");\n    }\n    // Generate crcTable\n    if (!crcTable.length) genCRCTable();\n\n    let len = buf.length;\n    let crc = ~0;\n    for (let off = 0; off < len; ) crc = Utils.crc32update(crc, buf[off++]);\n    // xor and cast as uint32 number\n    return ~crc >>> 0;\n};\n\nUtils.methodToString = function (/*Number*/ method) {\n    switch (method) {\n        case Constants.STORED:\n            return \"STORED (\" + method + \")\";\n        case Constants.DEFLATED:\n            return \"DEFLATED (\" + method + \")\";\n        default:\n            return \"UNSUPPORTED (\" + method + \")\";\n    }\n};\n\n// removes \"..\" style path elements\nUtils.canonical = function (/*string*/ path) {\n    if (!path) return \"\";\n    // trick normalize think path is absolute\n    var safeSuffix = pth.posix.normalize(\"/\" + path.split(\"\\\\\").join(\"/\"));\n    return pth.join(\".\", safeSuffix);\n};\n\n// make abolute paths taking prefix as root folder\nUtils.sanitize = function (/*string*/ prefix, /*string*/ name) {\n    prefix = pth.resolve(pth.normalize(prefix));\n    var parts = name.split(\"/\");\n    for (var i = 0, l = parts.length; i < l; i++) {\n        var path = pth.normalize(pth.join(prefix, parts.slice(i, l).join(pth.sep)));\n        if (path.indexOf(prefix) === 0) {\n            return path;\n        }\n    }\n    return pth.normalize(pth.join(prefix, pth.basename(name)));\n};\n\n// converts buffer, Uint8Array, string types to buffer\nUtils.toBuffer = function toBuffer(/*buffer, Uint8Array, string*/ input) {\n    if (Buffer.isBuffer(input)) {\n        return input;\n    } else if (input instanceof Uint8Array) {\n        return Buffer.from(input);\n    } else {\n        // expect string all other values are invalid and return empty buffer\n        return typeof input === \"string\" ? Buffer.from(input, \"utf8\") : Buffer.alloc(0);\n    }\n};\n\nUtils.readBigUInt64LE = function (/*Buffer*/ buffer, /*int*/ index) {\n    var slice = Buffer.from(buffer.slice(index, index + 8));\n    slice.swap64();\n\n    return parseInt(`0x${slice.toString(\"hex\")}`);\n};\n\nUtils.isWin = isWin; // Do we have windows system\nUtils.crcTable = crcTable;\n","var Utils = require(\"./util\"),\n    Headers = require(\"./headers\"),\n    Constants = Utils.Constants,\n    Methods = require(\"./methods\");\n\nmodule.exports = function (/*Buffer*/ input) {\n    var _entryHeader = new Headers.EntryHeader(),\n        _entryName = Buffer.alloc(0),\n        _comment = Buffer.alloc(0),\n        _isDirectory = false,\n        uncompressedData = null,\n        _extra = Buffer.alloc(0);\n\n    function getCompressedDataFromZip() {\n        if (!input || !Buffer.isBuffer(input)) {\n            return Buffer.alloc(0);\n        }\n        _entryHeader.loadDataHeaderFromBinary(input);\n        return input.slice(_entryHeader.realDataOffset, _entryHeader.realDataOffset + _entryHeader.compressedSize);\n    }\n\n    function crc32OK(data) {\n        // if bit 3 (0x08) of the general-purpose flags field is set, then the CRC-32 and file sizes are not known when the header is written\n        if ((_entryHeader.flags & 0x8) !== 0x8) {\n            if (Utils.crc32(data) !== _entryHeader.dataHeader.crc) {\n                return false;\n            }\n        } else {\n            // @TODO: load and check data descriptor header\n            // The fields in the local header are filled with zero, and the CRC-32 and size are appended in a 12-byte structure\n            // (optionally preceded by a 4-byte signature) immediately after the compressed data:\n        }\n        return true;\n    }\n\n    function decompress(/*Boolean*/ async, /*Function*/ callback, /*String, Buffer*/ pass) {\n        if (typeof callback === \"undefined\" && typeof async === \"string\") {\n            pass = async;\n            async = void 0;\n        }\n        if (_isDirectory) {\n            if (async && callback) {\n                callback(Buffer.alloc(0), Utils.Errors.DIRECTORY_CONTENT_ERROR); //si added error.\n            }\n            return Buffer.alloc(0);\n        }\n\n        var compressedData = getCompressedDataFromZip();\n\n        if (compressedData.length === 0) {\n            // File is empty, nothing to decompress.\n            if (async && callback) callback(compressedData);\n            return compressedData;\n        }\n\n        if (_entryHeader.encripted) {\n            if (\"string\" !== typeof pass && !Buffer.isBuffer(pass)) {\n                throw new Error(\"ADM-ZIP: Incompatible password parameter\");\n            }\n            compressedData = Methods.ZipCrypto.decrypt(compressedData, _entryHeader, pass);\n        }\n\n        var data = Buffer.alloc(_entryHeader.size);\n\n        switch (_entryHeader.method) {\n            case Utils.Constants.STORED:\n                compressedData.copy(data);\n                if (!crc32OK(data)) {\n                    if (async && callback) callback(data, Utils.Errors.BAD_CRC); //si added error\n                    throw new Error(Utils.Errors.BAD_CRC);\n                } else {\n                    //si added otherwise did not seem to return data.\n                    if (async && callback) callback(data);\n                    return data;\n                }\n            case Utils.Constants.DEFLATED:\n                var inflater = new Methods.Inflater(compressedData);\n                if (!async) {\n                    const result = inflater.inflate(data);\n                    result.copy(data, 0);\n                    if (!crc32OK(data)) {\n                        throw new Error(Utils.Errors.BAD_CRC + \" \" + _entryName.toString());\n                    }\n                    return data;\n                } else {\n                    inflater.inflateAsync(function (result) {\n                        result.copy(result, 0);\n                        if (callback) {\n                            if (!crc32OK(result)) {\n                                callback(result, Utils.Errors.BAD_CRC); //si added error\n                            } else {\n                                callback(result);\n                            }\n                        }\n                    });\n                }\n                break;\n            default:\n                if (async && callback) callback(Buffer.alloc(0), Utils.Errors.UNKNOWN_METHOD);\n                throw new Error(Utils.Errors.UNKNOWN_METHOD);\n        }\n    }\n\n    function compress(/*Boolean*/ async, /*Function*/ callback) {\n        if ((!uncompressedData || !uncompressedData.length) && Buffer.isBuffer(input)) {\n            // no data set or the data wasn't changed to require recompression\n            if (async && callback) callback(getCompressedDataFromZip());\n            return getCompressedDataFromZip();\n        }\n\n        if (uncompressedData.length && !_isDirectory) {\n            var compressedData;\n            // Local file header\n            switch (_entryHeader.method) {\n                case Utils.Constants.STORED:\n                    _entryHeader.compressedSize = _entryHeader.size;\n\n                    compressedData = Buffer.alloc(uncompressedData.length);\n                    uncompressedData.copy(compressedData);\n\n                    if (async && callback) callback(compressedData);\n                    return compressedData;\n                default:\n                case Utils.Constants.DEFLATED:\n                    var deflater = new Methods.Deflater(uncompressedData);\n                    if (!async) {\n                        var deflated = deflater.deflate();\n                        _entryHeader.compressedSize = deflated.length;\n                        return deflated;\n                    } else {\n                        deflater.deflateAsync(function (data) {\n                            compressedData = Buffer.alloc(data.length);\n                            _entryHeader.compressedSize = data.length;\n                            data.copy(compressedData);\n                            callback && callback(compressedData);\n                        });\n                    }\n                    deflater = null;\n                    break;\n            }\n        } else if (async && callback) {\n            callback(Buffer.alloc(0));\n        } else {\n            return Buffer.alloc(0);\n        }\n    }\n\n    function readUInt64LE(buffer, offset) {\n        return (buffer.readUInt32LE(offset + 4) << 4) + buffer.readUInt32LE(offset);\n    }\n\n    function parseExtra(data) {\n        var offset = 0;\n        var signature, size, part;\n        while (offset < data.length) {\n            signature = data.readUInt16LE(offset);\n            offset += 2;\n            size = data.readUInt16LE(offset);\n            offset += 2;\n            part = data.slice(offset, offset + size);\n            offset += size;\n            if (Constants.ID_ZIP64 === signature) {\n                parseZip64ExtendedInformation(part);\n            }\n        }\n    }\n\n    //Override header field values with values from the ZIP64 extra field\n    function parseZip64ExtendedInformation(data) {\n        var size, compressedSize, offset, diskNumStart;\n\n        if (data.length >= Constants.EF_ZIP64_SCOMP) {\n            size = readUInt64LE(data, Constants.EF_ZIP64_SUNCOMP);\n            if (_entryHeader.size === Constants.EF_ZIP64_OR_32) {\n                _entryHeader.size = size;\n            }\n        }\n        if (data.length >= Constants.EF_ZIP64_RHO) {\n            compressedSize = readUInt64LE(data, Constants.EF_ZIP64_SCOMP);\n            if (_entryHeader.compressedSize === Constants.EF_ZIP64_OR_32) {\n                _entryHeader.compressedSize = compressedSize;\n            }\n        }\n        if (data.length >= Constants.EF_ZIP64_DSN) {\n            offset = readUInt64LE(data, Constants.EF_ZIP64_RHO);\n            if (_entryHeader.offset === Constants.EF_ZIP64_OR_32) {\n                _entryHeader.offset = offset;\n            }\n        }\n        if (data.length >= Constants.EF_ZIP64_DSN + 4) {\n            diskNumStart = data.readUInt32LE(Constants.EF_ZIP64_DSN);\n            if (_entryHeader.diskNumStart === Constants.EF_ZIP64_OR_16) {\n                _entryHeader.diskNumStart = diskNumStart;\n            }\n        }\n    }\n\n    return {\n        get entryName() {\n            return _entryName.toString();\n        },\n        get rawEntryName() {\n            return _entryName;\n        },\n        set entryName(val) {\n            _entryName = Utils.toBuffer(val);\n            var lastChar = _entryName[_entryName.length - 1];\n            _isDirectory = lastChar === 47 || lastChar === 92;\n            _entryHeader.fileNameLength = _entryName.length;\n        },\n\n        get extra() {\n            return _extra;\n        },\n        set extra(val) {\n            _extra = val;\n            _entryHeader.extraLength = val.length;\n            parseExtra(val);\n        },\n\n        get comment() {\n            return _comment.toString();\n        },\n        set comment(val) {\n            _comment = Utils.toBuffer(val);\n            _entryHeader.commentLength = _comment.length;\n        },\n\n        get name() {\n            var n = _entryName.toString();\n            return _isDirectory\n                ? n\n                      .substr(n.length - 1)\n                      .split(\"/\")\n                      .pop()\n                : n.split(\"/\").pop();\n        },\n        get isDirectory() {\n            return _isDirectory;\n        },\n\n        getCompressedData: function () {\n            return compress(false, null);\n        },\n\n        getCompressedDataAsync: function (/*Function*/ callback) {\n            compress(true, callback);\n        },\n\n        setData: function (value) {\n            uncompressedData = Utils.toBuffer(value);\n            if (!_isDirectory && uncompressedData.length) {\n                _entryHeader.size = uncompressedData.length;\n                _entryHeader.method = Utils.Constants.DEFLATED;\n                _entryHeader.crc = Utils.crc32(value);\n                _entryHeader.changed = true;\n            } else {\n                // folders and blank files should be stored\n                _entryHeader.method = Utils.Constants.STORED;\n            }\n        },\n\n        getData: function (pass) {\n            if (_entryHeader.changed) {\n                return uncompressedData;\n            } else {\n                return decompress(false, null, pass);\n            }\n        },\n\n        getDataAsync: function (/*Function*/ callback, pass) {\n            if (_entryHeader.changed) {\n                callback(uncompressedData);\n            } else {\n                decompress(true, callback, pass);\n            }\n        },\n\n        set attr(attr) {\n            _entryHeader.attr = attr;\n        },\n        get attr() {\n            return _entryHeader.attr;\n        },\n\n        set header(/*Buffer*/ data) {\n            _entryHeader.loadFromBinary(data);\n        },\n\n        get header() {\n            return _entryHeader;\n        },\n\n        packHeader: function () {\n            // 1. create header (buffer)\n            var header = _entryHeader.entryHeaderToBinary();\n            var addpos = Utils.Constants.CENHDR;\n            // 2. add file name\n            _entryName.copy(header, addpos);\n            addpos += _entryName.length;\n            // 3. add extra data\n            if (_entryHeader.extraLength) {\n                _extra.copy(header, addpos);\n                addpos += _entryHeader.extraLength;\n            }\n            // 4. add file comment\n            if (_entryHeader.commentLength) {\n                _comment.copy(header, addpos);\n            }\n            return header;\n        },\n\n        toJSON: function () {\n            const bytes = function (nr) {\n                return \"<\" + ((nr && nr.length + \" bytes buffer\") || \"null\") + \">\";\n            };\n\n            return {\n                entryName: this.entryName,\n                name: this.name,\n                comment: this.comment,\n                isDirectory: this.isDirectory,\n                header: _entryHeader.toJSON(),\n                compressedData: bytes(input),\n                data: bytes(uncompressedData)\n            };\n        },\n\n        toString: function () {\n            return JSON.stringify(this.toJSON(), null, \"\\t\");\n        }\n    };\n};\n","const ZipEntry = require(\"./zipEntry\");\nconst Headers = require(\"./headers\");\nconst Utils = require(\"./util\");\n\nmodule.exports = function (/*Buffer|null*/ inBuffer, /** object */ options) {\n    var entryList = [],\n        entryTable = {},\n        _comment = Buffer.alloc(0),\n        mainHeader = new Headers.MainHeader(),\n        loadedEntries = false;\n\n    // assign options\n    const opts = Object.assign(Object.create(null), options);\n\n    const { noSort } = opts;\n\n    if (inBuffer) {\n        // is a memory buffer\n        readMainHeader(opts.readEntries);\n    } else {\n        // none. is a new file\n        loadedEntries = true;\n    }\n\n    function iterateEntries(callback) {\n        const totalEntries = mainHeader.diskEntries; // total number of entries\n        let index = mainHeader.offset; // offset of first CEN header\n\n        for (let i = 0; i < totalEntries; i++) {\n            let tmp = index;\n            const entry = new ZipEntry(inBuffer);\n\n            entry.header = inBuffer.slice(tmp, (tmp += Utils.Constants.CENHDR));\n            entry.entryName = inBuffer.slice(tmp, (tmp += entry.header.fileNameLength));\n\n            index += entry.header.entryHeaderSize;\n\n            callback(entry);\n        }\n    }\n\n    function readEntries() {\n        loadedEntries = true;\n        entryTable = {};\n        entryList = new Array(mainHeader.diskEntries); // total number of entries\n        var index = mainHeader.offset; // offset of first CEN header\n        for (var i = 0; i < entryList.length; i++) {\n            var tmp = index,\n                entry = new ZipEntry(inBuffer);\n            entry.header = inBuffer.slice(tmp, (tmp += Utils.Constants.CENHDR));\n\n            entry.entryName = inBuffer.slice(tmp, (tmp += entry.header.fileNameLength));\n\n            if (entry.header.extraLength) {\n                entry.extra = inBuffer.slice(tmp, (tmp += entry.header.extraLength));\n            }\n\n            if (entry.header.commentLength) entry.comment = inBuffer.slice(tmp, tmp + entry.header.commentLength);\n\n            index += entry.header.entryHeaderSize;\n\n            entryList[i] = entry;\n            entryTable[entry.entryName] = entry;\n        }\n    }\n\n    function readMainHeader(/*Boolean*/ readNow) {\n        var i = inBuffer.length - Utils.Constants.ENDHDR, // END header size\n            max = Math.max(0, i - 0xffff), // 0xFFFF is the max zip file comment length\n            n = max,\n            endStart = inBuffer.length,\n            endOffset = -1, // Start offset of the END header\n            commentEnd = 0;\n\n        for (i; i >= n; i--) {\n            if (inBuffer[i] !== 0x50) continue; // quick check that the byte is 'P'\n            if (inBuffer.readUInt32LE(i) === Utils.Constants.ENDSIG) {\n                // \"PK\\005\\006\"\n                endOffset = i;\n                commentEnd = i;\n                endStart = i + Utils.Constants.ENDHDR;\n                // We already found a regular signature, let's look just a bit further to check if there's any zip64 signature\n                n = i - Utils.Constants.END64HDR;\n                continue;\n            }\n\n            if (inBuffer.readUInt32LE(i) === Utils.Constants.END64SIG) {\n                // Found a zip64 signature, let's continue reading the whole zip64 record\n                n = max;\n                continue;\n            }\n\n            if (inBuffer.readUInt32LE(i) === Utils.Constants.ZIP64SIG) {\n                // Found the zip64 record, let's determine it's size\n                endOffset = i;\n                endStart = i + Utils.readBigUInt64LE(inBuffer, i + Utils.Constants.ZIP64SIZE) + Utils.Constants.ZIP64LEAD;\n                break;\n            }\n        }\n\n        if (!~endOffset) throw new Error(Utils.Errors.INVALID_FORMAT);\n\n        mainHeader.loadFromBinary(inBuffer.slice(endOffset, endStart));\n        if (mainHeader.commentLength) {\n            _comment = inBuffer.slice(commentEnd + Utils.Constants.ENDHDR);\n        }\n        if (readNow) readEntries();\n    }\n\n    function sortEntries() {\n        if (entryList.length > 1 && !noSort) {\n            entryList.sort((a, b) => a.entryName.toLowerCase().localeCompare(b.entryName.toLowerCase()));\n        }\n    }\n\n    return {\n        /**\n         * Returns an array of ZipEntry objects existent in the current opened archive\n         * @return Array\n         */\n        get entries() {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            return entryList;\n        },\n\n        /**\n         * Archive comment\n         * @return {String}\n         */\n        get comment() {\n            return _comment.toString();\n        },\n        set comment(val) {\n            _comment = Utils.toBuffer(val);\n            mainHeader.commentLength = _comment.length;\n        },\n\n        getEntryCount: function () {\n            if (!loadedEntries) {\n                return mainHeader.diskEntries;\n            }\n\n            return entryList.length;\n        },\n\n        forEach: function (callback) {\n            if (!loadedEntries) {\n                iterateEntries(callback);\n                return;\n            }\n\n            entryList.forEach(callback);\n        },\n\n        /**\n         * Returns a reference to the entry with the given name or null if entry is inexistent\n         *\n         * @param entryName\n         * @return ZipEntry\n         */\n        getEntry: function (/*String*/ entryName) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            return entryTable[entryName] || null;\n        },\n\n        /**\n         * Adds the given entry to the entry list\n         *\n         * @param entry\n         */\n        setEntry: function (/*ZipEntry*/ entry) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            entryList.push(entry);\n            entryTable[entry.entryName] = entry;\n            mainHeader.totalEntries = entryList.length;\n        },\n\n        /**\n         * Removes the entry with the given name from the entry list.\n         *\n         * If the entry is a directory, then all nested files and directories will be removed\n         * @param entryName\n         */\n        deleteEntry: function (/*String*/ entryName) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            var entry = entryTable[entryName];\n            if (entry && entry.isDirectory) {\n                var _self = this;\n                this.getEntryChildren(entry).forEach(function (child) {\n                    if (child.entryName !== entryName) {\n                        _self.deleteEntry(child.entryName);\n                    }\n                });\n            }\n            entryList.splice(entryList.indexOf(entry), 1);\n            delete entryTable[entryName];\n            mainHeader.totalEntries = entryList.length;\n        },\n\n        /**\n         *  Iterates and returns all nested files and directories of the given entry\n         *\n         * @param entry\n         * @return Array\n         */\n        getEntryChildren: function (/*ZipEntry*/ entry) {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            if (entry && entry.isDirectory) {\n                const list = [];\n                const name = entry.entryName;\n                const len = name.length;\n\n                entryList.forEach(function (zipEntry) {\n                    if (zipEntry.entryName.substr(0, len) === name) {\n                        list.push(zipEntry);\n                    }\n                });\n                return list;\n            }\n            return [];\n        },\n\n        /**\n         * Returns the zip file\n         *\n         * @return Buffer\n         */\n        compressToBuffer: function () {\n            if (!loadedEntries) {\n                readEntries();\n            }\n            sortEntries();\n\n            const dataBlock = [];\n            const entryHeaders = [];\n            let totalSize = 0;\n            let dindex = 0;\n\n            mainHeader.size = 0;\n            mainHeader.offset = 0;\n\n            for (const entry of entryList) {\n                // compress data and set local and entry header accordingly. Reason why is called first\n                const compressedData = entry.getCompressedData();\n                // 1. construct data header\n                entry.header.offset = dindex;\n                const dataHeader = entry.header.dataHeaderToBinary();\n                const entryNameLen = entry.rawEntryName.length;\n                // 1.2. postheader - data after data header\n                const postHeader = Buffer.alloc(entryNameLen + entry.extra.length);\n                entry.rawEntryName.copy(postHeader, 0);\n                postHeader.copy(entry.extra, entryNameLen);\n\n                // 2. offsets\n                const dataLength = dataHeader.length + postHeader.length + compressedData.length;\n                dindex += dataLength;\n\n                // 3. store values in sequence\n                dataBlock.push(dataHeader);\n                dataBlock.push(postHeader);\n                dataBlock.push(compressedData);\n\n                // 4. construct entry header\n                const entryHeader = entry.packHeader();\n                entryHeaders.push(entryHeader);\n                // 5. update main header\n                mainHeader.size += entryHeader.length;\n                totalSize += dataLength + entryHeader.length;\n            }\n\n            totalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\n            // point to end of data and beginning of central directory first record\n            mainHeader.offset = dindex;\n\n            dindex = 0;\n            const outBuffer = Buffer.alloc(totalSize);\n            // write data blocks\n            for (const content of dataBlock) {\n                content.copy(outBuffer, dindex);\n                dindex += content.length;\n            }\n\n            // write central directory entries\n            for (const content of entryHeaders) {\n                content.copy(outBuffer, dindex);\n                dindex += content.length;\n            }\n\n            // write main header\n            const mh = mainHeader.toBinary();\n            if (_comment) {\n                _comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\n            }\n            mh.copy(outBuffer, dindex);\n\n            return outBuffer;\n        },\n\n        toAsyncBuffer: function (/*Function*/ onSuccess, /*Function*/ onFail, /*Function*/ onItemStart, /*Function*/ onItemEnd) {\n            try {\n                if (!loadedEntries) {\n                    readEntries();\n                }\n                sortEntries();\n\n                const dataBlock = [];\n                const entryHeaders = [];\n                let totalSize = 0;\n                let dindex = 0;\n\n                mainHeader.size = 0;\n                mainHeader.offset = 0;\n\n                const compress2Buffer = function (entryLists) {\n                    if (entryLists.length) {\n                        const entry = entryLists.pop();\n                        const name = entry.entryName + entry.extra.toString();\n                        if (onItemStart) onItemStart(name);\n                        entry.getCompressedDataAsync(function (compressedData) {\n                            if (onItemEnd) onItemEnd(name);\n\n                            entry.header.offset = dindex;\n                            // data header\n                            const dataHeader = entry.header.dataHeaderToBinary();\n                            const postHeader = Buffer.alloc(name.length, name);\n                            const dataLength = dataHeader.length + postHeader.length + compressedData.length;\n\n                            dindex += dataLength;\n\n                            dataBlock.push(dataHeader);\n                            dataBlock.push(postHeader);\n                            dataBlock.push(compressedData);\n\n                            const entryHeader = entry.packHeader();\n                            entryHeaders.push(entryHeader);\n                            mainHeader.size += entryHeader.length;\n                            totalSize += dataLength + entryHeader.length;\n\n                            compress2Buffer(entryLists);\n                        });\n                    } else {\n                        totalSize += mainHeader.mainHeaderSize; // also includes zip file comment length\n                        // point to end of data and beginning of central directory first record\n                        mainHeader.offset = dindex;\n\n                        dindex = 0;\n                        const outBuffer = Buffer.alloc(totalSize);\n                        dataBlock.forEach(function (content) {\n                            content.copy(outBuffer, dindex); // write data blocks\n                            dindex += content.length;\n                        });\n                        entryHeaders.forEach(function (content) {\n                            content.copy(outBuffer, dindex); // write central directory entries\n                            dindex += content.length;\n                        });\n\n                        const mh = mainHeader.toBinary();\n                        if (_comment) {\n                            _comment.copy(mh, Utils.Constants.ENDHDR); // add zip file comment\n                        }\n\n                        mh.copy(outBuffer, dindex); // write main header\n\n                        onSuccess(outBuffer);\n                    }\n                };\n\n                compress2Buffer(entryList);\n            } catch (e) {\n                onFail(e);\n            }\n        }\n    };\n};\n",null,"import path from \"path\";\nimport fs from \"fs/promises\";\nimport os from \"os\";\nimport { useRuntimeHandlers } from \"../handlers.js\";\nimport { useRuntimeWorkers } from \"../workers.js\";\nimport { Context } from \"../../context/context.js\";\nimport { spawn } from \"child_process\";\nimport { useRuntimeServerConfig } from \"../server.js\";\nimport { existsAsync, findBelow, isChild } from \"../../util/fs.js\";\nimport { useProject } from \"../../project.js\";\nimport { execAsync } from \"../../util/process.js\";\nimport url from \"url\";\nimport AdmZip from \"adm-zip\";\nexport const useJavaHandler = Context.memo(async () => {\n    const workers = await useRuntimeWorkers();\n    const server = await useRuntimeServerConfig();\n    const handlers = useRuntimeHandlers();\n    const processes = new Map();\n    const sources = new Map();\n    const handlerName = process.platform === \"win32\" ? `handler.exe` : `handler`;\n    handlers.register({\n        shouldBuild: (input) => {\n            if (!input.file.endsWith(\".java\"))\n                return false;\n            const parent = sources.get(input.functionID);\n            if (!parent)\n                return false;\n            return isChild(parent, input.file);\n        },\n        canHandle: (input) => input.startsWith(\"java\"),\n        startWorker: async (input) => {\n            const proc = spawn(`java`, [\n                `-cp`,\n                [\n                    url.fileURLToPath(new URL(\"../../support/java-runtime/release/*\", import.meta.url)),\n                ].join(os.platform() === \"win32\" ? \";\" : \":\"),\n                \"com.amazonaws.services.lambda.runtime.api.client.AWSLambda\",\n                input.handler,\n            ], {\n                env: {\n                    ...process.env,\n                    ...input.environment,\n                    IS_LOCAL: \"true\",\n                    AWS_LAMBDA_RUNTIME_API: `localhost:${server.port}/${input.workerID}`,\n                },\n                cwd: input.out,\n            });\n            proc.on(\"exit\", () => workers.exited(input.workerID));\n            proc.stdout.on(\"data\", (data) => {\n                workers.stdout(input.workerID, data.toString());\n            });\n            proc.stderr.on(\"data\", (data) => {\n                workers.stdout(input.workerID, data.toString());\n            });\n            processes.set(input.workerID, proc);\n        },\n        stopWorker: async (workerID) => {\n            const proc = processes.get(workerID);\n            if (proc) {\n                proc.kill();\n                processes.delete(workerID);\n            }\n        },\n        build: async (input) => {\n            const project = useProject();\n            const srcPath = await findBelow(project.paths.root, \"build.gradle\");\n            const buildBinary = await getGradleBinary(srcPath);\n            const buildTask = input.props.java?.buildTask || \"build\";\n            const outputDir = input.props.java?.buildOutputDir || \"distributions\";\n            sources.set(input.functionID, srcPath);\n            try {\n                await execAsync(`${buildBinary} ${buildTask} -Dorg.gradle.logging.level=${process.env.DEBUG ? \"debug\" : \"lifecycle\"}`, {\n                    cwd: srcPath,\n                });\n                const buildOutput = path.join(srcPath, \"build\", outputDir);\n                const zip = (await fs.readdir(buildOutput)).find((f) => f.endsWith(\".zip\"));\n                new AdmZip(path.join(buildOutput, zip)).extractAllTo(input.out);\n                return {\n                    type: \"success\",\n                    handler: input.props.handler,\n                };\n            }\n            catch (ex) {\n                return {\n                    type: \"error\",\n                    errors: [ex.stderr],\n                };\n            }\n        },\n    });\n});\nasync function getGradleBinary(srcPath) {\n    // Use a gradle wrapper if provided in the folder, otherwise fall back\n    // to system \"gradle\"\n    const gradleWrapperPath = path.resolve(path.join(srcPath, \"gradlew\"));\n    return (await existsAsync(gradleWrapperPath)) ? gradleWrapperPath : \"gradle\";\n}\n"],"names":[],"sourceRoot":""}